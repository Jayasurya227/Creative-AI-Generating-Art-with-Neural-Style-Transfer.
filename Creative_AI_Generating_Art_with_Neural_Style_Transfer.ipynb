{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/HEU7pR8dVPe7d0bHI5K0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayasurya227/Creative-AI-Generating-Art-with-Neural-Style-Transfer./blob/main/Creative_AI_Generating_Art_with_Neural_Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Face Generator With GAN**"
      ],
      "metadata": {
        "id": "JOXucRZZfFzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "IMAGE_SHAPE = (128, 128, 3)\n",
        "NOISE_DIM = 100\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 50\n",
        "DATA_PATH = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/'\n",
        "def preprocess_image(file_path):\n",
        "    img_raw = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img_raw, channels=3)\n",
        "    img = tf.image.resize(img, (IMAGE_SHAPE[0], IMAGE_SHAPE[1]))\n",
        "    img = (img / 127.5) - 1.0  # Normalize to [-1, 1]\n",
        "    return img\n",
        "\n",
        "def load_celeba_images(path):\n",
        "    all_files = [os.path.join(path, f) for f in os.listdir(path)[:10000] if f.endswith('.jpg')]\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(all_files)\n",
        "    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    images_list = []\n",
        "    for batch in tqdm(dataset.batch(1024).prefetch(tf.data.AUTOTUNE)):\n",
        "        images_list.append(batch)\n",
        "\n",
        "    return tf.concat(images_list, axis=0)\n",
        "\n",
        "images = load_celeba_images(DATA_PATH)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(images) \\\n",
        "                         .shuffle(buffer_size=50000) \\\n",
        "                         .batch(BATCH_SIZE) \\\n",
        "                         .prefetch(tf.data.AUTOTUNE)\n",
        "\n"
      ],
      "metadata": {
        "id": "hpjD2QNMPebO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_generator(NOISE_DIM=NOISE_DIM):\n",
        "    model = tf.keras.Sequential([\n",
        "        # 1) Start with a dense layer that reshapes to 8x8 with 512 channels\n",
        "        layers.Dense(8*8*512, use_bias=False, input_shape=(NOISE_DIM,)),\n",
        "        layers.Reshape((8, 8, 512)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "        # 2) Upsample to 16x16\n",
        "        layers.Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "\n",
        "        # 3) Upsample to 32x32\n",
        "        layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "        # 4) Upsample to 64x64\n",
        "        layers.Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "\n",
        "        # 5) Upsample to 128x128\n",
        "        layers.Conv2DTranspose(32, (4,4), strides=(2,2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "\n",
        "        # 6) Final layer â†’ 128x128x3, use tanh for output in [-1,1]\n",
        "        layers.Conv2DTranspose(3, (4,4), strides=(1,1), padding='same', use_bias=False, activation='tanh')\n",
        "    ], name=\"Generator\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential([\n",
        "        # 1) Downsample from 128x128 to 64x64\n",
        "        layers.Conv2D(64, (4,4), strides=(2,2), padding='same',\n",
        "                      input_shape=(128,128,3)),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        # 2) Downsample to 32x32\n",
        "        layers.Conv2D(128, (4,4), strides=(2,2), padding='same'),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),\n",
        "        # 3) Downsample to 16x16\n",
        "        layers.Conv2D(256, (4,4), strides=(2,2), padding='same'),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        # 4) Downsample to 8x8\n",
        "        layers.Conv2D(512, (4,4), strides=(2,2), padding='same'),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        # 5) Flatten to a single logit\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1)\n",
        "    ], name=\"Discriminator\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "4Df6BGpKffI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "    gen_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "disc_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "3L5EqXNEfxl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(real_images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        # Ensure shapes match\n",
        "        assert generated_images.shape[1:] == IMAGE_SHAPE, \"Generated image shape mismatch!\"\n",
        "        assert real_images.shape[1:] == IMAGE_SHAPE, \"Real image shape mismatch!\"\n",
        "\n",
        "        real_output = discriminator(real_images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "        g_loss = generator_loss(fake_output)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
        "\n",
        "    gen_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    disc_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return g_loss, d_loss\n",
        "    def generate_and_show_images(noise):\n",
        "    # Generate images\n",
        "    preds = generator(noise, training=False)\n",
        "    preds = (preds + 1) / 2.0  # Shift from [-1,1] to [0,1]\n",
        "\n",
        "    # Plot\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    for i in range(preds.shape[0]):\n",
        "        plt.subplot(4,4,i+1)\n",
        "        plt.imshow(preds[i])\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dRD3P89mf4-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
        "\n",
        "with strategy.scope():\n",
        "    generator = build_generator()\n",
        "    discriminator = build_discriminator()\n",
        "\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "    def generator_loss(fake_output):\n",
        "        return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "        def discriminator_loss(real_output, fake_output):\n",
        "        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    gen_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "    disc_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "# Existing dataset creation\n",
        "dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(10000).batch(BATCH_SIZE)\n",
        "# Make a distributed dataset\n",
        "dist_dataset = strategy.experimental_distribute_dataset(dataset)\n",
        "\n",
        "@tf.function\n",
        "\n",
        "def distributed_train_step(dataset_inputs):\n",
        "    def step_fn(real_images):\n",
        "        return train_step(real_images)  # The train_step you already have\n",
        "\n",
        "    per_replica_g_loss, per_replica_d_loss = strategy.run(step_fn, args=(dataset_inputs,))\n",
        "    mean_g_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_g_loss, axis=None)\n",
        "    mean_d_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_d_loss, axis=None)\n",
        "    return mean_g_loss, mean_d_loss\n",
        "    def train(dataset, epochs):\n",
        "    fixed_noise = tf.random.normal([16, NOISE_DIM])\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        g_losses = []\n",
        "        d_losses = []\n",
        "\n",
        "        for image_batch in dist_dataset:  # Use distributed dataset\n",
        "            g_loss, d_loss = distributed_train_step(image_batch)\n",
        "            g_losses.append(g_loss)\n",
        "            d_losses.append(d_loss)\n",
        "            avg_g_loss = tf.reduce_mean(g_losses)\n",
        "        avg_d_loss = tf.reduce_mean(d_losses)\n",
        "\n",
        "        epoch_duration = time.time() - epoch_start_time\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Generator loss: {avg_g_loss:.4f}, \"\n",
        "              f\"Discriminator loss: {avg_d_loss:.4f} | \"\n",
        "              f\"Time: {epoch_duration:.2f} s\")\n",
        "\n",
        "        generate_and_show_images(fixed_noise)\n",
        "\n",
        "    total_duration = time.time() - total_start_time\n",
        "    print(f\"\\nTotal Training Time: {total_duration:.2f} seconds\")"
      ],
      "metadata": {
        "id": "l9ZnHFf_gEii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(dataset, 100)\n",
        "generator.save('generator_800.h5')"
      ],
      "metadata": {
        "id": "OpbDIId8gXnz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}